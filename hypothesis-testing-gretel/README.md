## Hypothesis testing to figure out why the synthetically generated dataset by gretel.ai tends to miss out on certain variables

**Observation**: 5 binary variables(cough, fever, throat, breathing, malaise) corresponding to the symptoms recorded due to COVID, despite showing higher correlation amongst them 
than any other variables in the dataset, fail to get picked up by the gretel algorithm and do not get translated into the synthetically generated data. Surprisingly,
Gretel’s report comparing the two datasets(seed, syn) claims that the distance between these 5 features is not much despite their complete missingness. 


**Hypothesis**: The cause for these low distance scores may be the low number of unique values these columns contain since they’re binary variables, leading to gretel undermining their importance during data generation. 

**Hypothesis testing**: For the sake of testing, we replace the binary data points with more elaborate categorical data values, for instance on a scale of 0-10, with a threshold at 5.
We then observe the distance scores and whether the new synthetic data now contains these points or not. 

**Result**: It is observed that gretel considers `Unique(%)` as one of its parameteres wrt features during the data generation process, which accounts for the 
number of unique values the data points for that particular feature have. For instance, for binary variables, it's only 2(pretty low). Upon increasing the scale 
over which symptoms are expressed and making the data more sensitive in this regard,we find that these features are now included in the synthetic dataset generated by gretel. 


(Experimentation and Compilation work: [Keerat Kaur Guliani](https://github.com/KeeratKG);
Supporting members: Burhan, Kevin, Jay) 
